{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "2f8b992a",
   "metadata": {},
   "outputs": [],
   "source": [
    "%run jupyterutils.py\n",
    "\n",
    "from linear_regression.LinearRegression import LinearRegression"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9726de96",
   "metadata": {},
   "source": [
    "### Linear Regression .ipynb file\n",
    "We attempt to try and mimic linear regression and than test it , to test our implementations correctness we would generate the data set using a perfect linear equation , we will than compare how good our algorithm does when it get's data fitting a curve whose mathematically model is known. Run time and correctness might be good KPI for monitoring .\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0fa6328b",
   "metadata": {},
   "source": [
    "##### Create data\n",
    "\n",
    "We'll check how good is the algorithm in finding the actual parameters when we feed it absolutely ideal data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f636a270",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "y = 9.8⋅x₁ + 3.2⋅x₂ + 7.6\n"
     ]
    }
   ],
   "source": [
    "x1 = sp.Symbol('x1')\n",
    "x2 = sp.Symbol('x2')\n",
    "y = 9.8 * x1 + 3.2*x2 + 7.6\n",
    "print(\"y = \", end='')\n",
    "sp.pprint(y)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "2277fa63",
   "metadata": {},
   "outputs": [],
   "source": [
    "def ModelEquation(x1,x2):\n",
    "    return 9.8*x1 + 3.2*x2 + 7.6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "ea358307",
   "metadata": {},
   "outputs": [],
   "source": [
    "total_data_points = 50000\n",
    "x1 = np.linspace(0, 2, total_data_points)\n",
    "x2 = np.linspace(0, 2, total_data_points)\n",
    "y = ModelEquation(x1,x2)\n",
    "\n",
    "perm = np.random.permutation(len(x1))\n",
    "x1 = x1[perm]\n",
    "x2 = x2[perm]\n",
    "y = y[perm]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "044f62c7",
   "metadata": {},
   "source": [
    "##### Split data\n",
    "\n",
    "We're going to split the data into training and testing data based on a tuneable parameter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "a43ab785",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(42500, 2)\n",
      "(7500, 2)\n",
      "(42500,)\n",
      "(7500,)\n"
     ]
    }
   ],
   "source": [
    "training_percent = 0.85\n",
    "training_numbers = int(training_percent*total_data_points)\n",
    "\n",
    "training_features = np.array([x1[:training_numbers],x2[:training_numbers]]).T\n",
    "training_labels = np.array(y[:training_numbers])\n",
    "\n",
    "testing_attributes=np.array([x1[training_numbers:],x2[training_numbers:]]).T\n",
    "testing_labels=np.array(y[training_numbers:])\n",
    "\n",
    "print(training_features.shape)\n",
    "print(testing_attributes.shape)\n",
    "print(training_labels.shape)\n",
    "print(testing_labels.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8deb1efb",
   "metadata": {},
   "source": [
    "##### Model Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "2dbaf349",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration  0  weights  [[0.20163077]\n",
      " [0.83958971]]  bias  0.003912885382747765 loss 430.6101852248992\n",
      "Iteration  1000  weights  [[3.58739868]\n",
      " [4.22535762]]  bias  2.843875943956715 loss 107.97416011194892\n",
      "Iteration  2000  weights  [[5.26219305]\n",
      " [5.90015199]]  bias  4.29745633540204 loss 27.580710526026994\n",
      "Iteration  3000  weights  [[6.08376028]\n",
      " [6.72171922]]  bias  5.057852287823786 loss 7.510936034117539\n",
      "Iteration  4000  weights  [[6.48009814]\n",
      " [7.11805707]]  bias  5.471024198137336 loss 2.4658526150311393\n",
      "Iteration  5000  weights  [[6.664759  ]\n",
      " [7.30271793]]  bias  5.709657507121143 loss 1.1655139720698984\n",
      "Iteration  6000  weights  [[6.74428691]\n",
      " [7.38224585]]  bias  5.859970910526429 loss 0.800898409808911\n",
      "Iteration  7000  weights  [[6.77182911]\n",
      " [7.40978804]]  bias  5.965034058093847 loss 0.672304447074799\n",
      "Iteration  8000  weights  [[6.77388829]\n",
      " [7.41184723]]  bias  6.046383318687671 loss 0.6052793481444125\n",
      "Iteration  9000  weights  [[6.76367215]\n",
      " [7.40163109]]  bias  6.114808195175248 loss 0.5561763968790023\n",
      "Iteration  10000  weights  [[6.74775472]\n",
      " [7.38571366]]  bias  6.1757338497969565 loss 0.5139355381333106\n",
      "Iteration  11000  weights  [[6.72940048]\n",
      " [7.36735942]]  bias  6.2319070656993585 loss 0.47562515074593925\n",
      "Iteration  12000  weights  [[6.71022303]\n",
      " [7.34818197]]  bias  6.284736610545387 loss 0.4403507805003881\n",
      "Iteration  13000  weights  [[6.69101273]\n",
      " [7.32897167]]  bias  6.334962139425458 loss 0.40773741211752657\n",
      "Iteration  14000  weights  [[6.67214972]\n",
      " [7.31010866]]  bias  6.38298803419583 loss 0.3775506464734453\n",
      "Iteration  15000  weights  [[6.65380998]\n",
      " [7.29176892]]  bias  6.429050042771546 loss 0.349601537399883\n",
      "Iteration  16000  weights  [[6.63606811]\n",
      " [7.27402705]]  bias  6.4732984829910505 loss 0.3237221228569695\n",
      "Iteration  17000  weights  [[6.61894864]\n",
      " [7.25690758]]  bias  6.515839809989531 loss 0.29975861654549024\n",
      "Iteration  18000  weights  [[6.60245159]\n",
      " [7.24041053]]  bias  6.556757404981558 loss 0.27756905002047394\n",
      "Iteration  19000  weights  [[6.58656519]\n",
      " [7.22452413]]  bias  6.596121993693206 loss 0.25702207204728494\n",
      "Iteration  20000  weights  [[6.57127226]\n",
      " [7.2092312 ]]  bias  6.633996888261882 loss 0.23799608153207297\n",
      "Iteration  21000  weights  [[6.55655334]\n",
      " [7.19451228]]  bias  6.670440644402185 loss 0.22037848556763467\n",
      "Iteration  22000  weights  [[6.54238822]\n",
      " [7.18034716]]  bias  6.705508427216388 loss 0.20406502757433237\n",
      "Iteration  23000  weights  [[6.52875674]\n",
      " [7.16671567]]  bias  6.739252731109682 loss 0.18895916895301207\n",
      "Iteration  24000  weights  [[6.51563913]\n",
      " [7.15359806]]  bias  6.771723775953515 loss 0.1749715174517018\n",
      "Iteration  25000  weights  [[6.50301618]\n",
      " [7.14097512]]  bias  6.802969740302727 loss 0.16201929808151525\n",
      "Iteration  26000  weights  [[6.49086934]\n",
      " [7.12882828]]  bias  6.833036911961557 loss 0.15002586325619233\n",
      "Iteration  27000  weights  [[6.47918067]\n",
      " [7.11713961]]  bias  6.861969796016686 loss 0.1389202392079732\n",
      "Iteration  28000  weights  [[6.46793293]\n",
      " [7.10589187]]  bias  6.889811200404996 loss 0.12863670598348909\n",
      "Iteration  29000  weights  [[6.45710948]\n",
      " [7.09506842]]  bias  6.916602309076769 loss 0.11911440853129598\n",
      "Iteration  30000  weights  [[6.44669433]\n",
      " [7.08465327]]  bias  6.942382747819777 loss 0.11029699657873554\n",
      "Iteration  31000  weights  [[6.43667208]\n",
      " [7.07463102]]  bias  6.967190645315176 loss 0.1021322911668871\n",
      "Iteration  32000  weights  [[6.4270279 ]\n",
      " [7.06498684]]  bias  6.991062690749944 loss 0.09457197587018328\n",
      "Iteration  33000  weights  [[6.41774754]\n",
      " [7.05570648]]  bias  7.014034188686968 loss 0.08757131087342213\n",
      "Iteration  34000  weights  [[6.40881728]\n",
      " [7.04677621]]  bias  7.0361391115812095 loss 0.08108886821415473\n",
      "Iteration  35000  weights  [[6.40022389]\n",
      " [7.03818283]]  bias  7.057410150173195 loss 0.07508628662367244\n",
      "Iteration  36000  weights  [[6.39195468]\n",
      " [7.02991362]]  bias  7.077878761910695 loss 0.0695280445158327\n",
      "Iteration  37000  weights  [[6.38399742]\n",
      " [7.02195636]]  bias  7.0975752175084885 loss 0.06438124978032514\n",
      "Iteration  38000  weights  [[6.37634034]\n",
      " [7.01429928]]  bias  7.116528645734137 loss 0.05961544513642712\n",
      "Iteration  39000  weights  [[6.36897211]\n",
      " [7.00693105]]  bias  7.134767076495418 loss 0.055202427895400655\n",
      "Iteration  40000  weights  [[6.36188184]\n",
      " [6.99984078]]  bias  7.152317482297949 loss 0.051116083064944105\n",
      "Iteration  41000  weights  [[6.35505905]\n",
      " [6.99301799]]  bias  7.1692058181368274 loss 0.04733222880799779\n",
      "Iteration  42000  weights  [[6.34849363]\n",
      " [6.98645257]]  bias  7.185457059882072 loss 0.043828473341477436\n",
      "Iteration  43000  weights  [[6.34217589]\n",
      " [6.98013483]]  bias  7.201095241215678 loss 0.04058408242799468\n",
      "Iteration  44000  weights  [[6.33609648]\n",
      " [6.97405542]]  bias  7.216143489174805 loss 0.03757985667649331\n",
      "Iteration  45000  weights  [[6.33024641]\n",
      " [6.96820535]]  bias  7.230624058354203 loss 0.03479801792566263\n",
      "Iteration  46000  weights  [[6.32461703]\n",
      " [6.96257597]]  bias  7.2445583638182205 loss 0.032222104037773806\n",
      "Iteration  47000  weights  [[6.3192    ]\n",
      " [6.95715894]]  bias  7.257967012771117 loss 0.029836871480416072\n",
      "Iteration  48000  weights  [[6.31398733]\n",
      " [6.95194627]]  bias  7.270869835032804 loss 0.027628205119542434\n",
      "Iteration  49000  weights  [[6.30897131]\n",
      " [6.94693025]]  bias  7.283285912364798 loss 0.025583034690099447\n",
      "Iteration  50000  weights  [[6.3041445 ]\n",
      " [6.94210344]]  bias  7.295233606689919 loss 0.0236892574498786\n",
      "Iteration  51000  weights  [[6.29949978]\n",
      " [6.93745872]]  bias  7.306730587247457 loss 0.021935666558892283\n",
      "Iteration  52000  weights  [[6.29503028]\n",
      " [6.93298922]]  bias  7.317793856723854 loss 0.020311884760463632\n",
      "Iteration  53000  weights  [[6.29072939]\n",
      " [6.92868833]]  bias  7.328439776397695 loss 0.018808302971541957\n",
      "Iteration  54000  weights  [[6.28659074]\n",
      " [6.92454968]]  bias  7.33868409033613 loss 0.01741602341885551\n",
      "Iteration  55000  weights  [[6.28260822]\n",
      " [6.92056716]]  bias  7.348541948678559 loss 0.016126806984394976\n",
      "Iteration  56000  weights  [[6.27877594]\n",
      " [6.91673488]]  bias  7.35802793004179 loss 0.014933024448645608\n",
      "Iteration  57000  weights  [[6.27508822]\n",
      " [6.91304716]]  bias  7.367156063080216 loss 0.013827611343003678\n",
      "Iteration  58000  weights  [[6.27153962]\n",
      " [6.90949856]]  bias  7.375939847232506 loss 0.01280402614424892\n",
      "Iteration  59000  weights  [[6.26812488]\n",
      " [6.90608382]]  bias  7.384392272685693 loss 0.01185621156365088\n",
      "Iteration  60000  weights  [[6.26483897]\n",
      " [6.90279791]]  bias  7.392525839586119 loss 0.01097855870164689\n",
      "Iteration  61000  weights  [[6.26167701]\n",
      " [6.89963595]]  bias  7.400352576525736 loss 0.01016587385594812\n",
      "Iteration  62000  weights  [[6.25863433]\n",
      " [6.89659327]]  bias  7.407884058330923 loss 0.009413347786676088\n",
      "Iteration  63000  weights  [[6.25570643]\n",
      " [6.89366537]]  bias  7.415131423180344 loss 0.008716527256640117\n",
      "Iteration  64000  weights  [[6.25288899]\n",
      " [6.89084793]]  bias  7.422105389077029 loss 0.008071288678324295\n",
      "Iteration  65000  weights  [[6.25017783]\n",
      " [6.88813677]]  bias  7.428816269698935 loss 0.0074738137116739526\n",
      "Iteration  66000  weights  [[6.24756895]\n",
      " [6.88552789]]  bias  7.435273989651796 loss 0.0069205666682208965\n",
      "Iteration  67000  weights  [[6.24505848]\n",
      " [6.88301742]]  bias  7.441488099146371 loss 0.006408273587885099\n",
      "Iteration  68000  weights  [[6.24264272]\n",
      " [6.88060166]]  bias  7.447467788122122 loss 0.005933902864596247\n",
      "Iteration  69000  weights  [[6.24031809]\n",
      " [6.87827703]]  bias  7.4532218998380175 loss 0.005494647306107216\n",
      "Iteration  70000  weights  [[6.23808115]\n",
      " [6.87604009]]  bias  7.458758943950741 loss 0.005087907521816242\n",
      "Iteration  71000  weights  [[6.2359286 ]\n",
      " [6.87388754]]  bias  7.464087109099432 loss 0.004711276540312233\n",
      "Iteration  72000  weights  [[6.23385726]\n",
      " [6.87181619]]  bias  7.4692142750156965 loss 0.004362525565593625\n",
      "Iteration  73000  weights  [[6.23186405]\n",
      " [6.86982299]]  bias  7.474148024176874 loss 0.004039590787679426\n",
      "Iteration  74000  weights  [[6.22994603]\n",
      " [6.86790497]]  bias  7.47889565301958 loss 0.003740561169567813\n",
      "Iteration  75000  weights  [[6.22810037]\n",
      " [6.86605931]]  bias  7.483464182730311 loss 0.003463667138253978\n",
      "Iteration  76000  weights  [[6.22632433]\n",
      " [6.86428327]]  bias  7.487860369628907 loss 0.0032072701128981105\n",
      "Iteration  77000  weights  [[6.2246153 ]\n",
      " [6.86257424]]  bias  7.492090715160473 loss 0.0029698528081627596\n",
      "Iteration  78000  weights  [[6.22297073]\n",
      " [6.86092967]]  bias  7.4961614755100685 loss 0.0027500102553527092\n",
      "Iteration  79000  weights  [[6.22138821]\n",
      " [6.85934715]]  bias  7.500078670855066 loss 0.0025464414881965786\n",
      "Iteration  80000  weights  [[6.21986538]\n",
      " [6.85782432]]  bias  7.503848094268141 loss 0.002357941844103651\n",
      "Iteration  81000  weights  [[6.2184    ]\n",
      " [6.85635894]]  bias  7.507475320284656 loss 0.0021833958353035254\n",
      "Iteration  82000  weights  [[6.2169899 ]\n",
      " [6.85494884]]  bias  7.510965713146638 loss 0.0020217705477103124\n",
      "Iteration  83000  weights  [[6.21563299]\n",
      " [6.85359193]]  bias  7.514324434735951 loss 0.0018721095284221305\n",
      "Iteration  84000  weights  [[6.21432728]\n",
      " [6.85228622]]  bias  7.517556452208097 loss 0.001733527125705411\n",
      "Iteration  85000  weights  [[6.21307082]\n",
      " [6.85102976]]  bias  7.520666545338003 loss 0.001605203247957848\n",
      "Iteration  86000  weights  [[6.21186175]\n",
      " [6.84982069]]  bias  7.5236593135888095 loss 0.0014863785106371417\n",
      "Iteration  87000  weights  [[6.2106983 ]\n",
      " [6.84865724]]  bias  7.526539182913917 loss 0.001376349742436101\n",
      "Iteration  88000  weights  [[6.20957874]\n",
      " [6.84753768]]  bias  7.529310412302455 loss 0.0012744658241134943\n",
      "Iteration  89000  weights  [[6.20850141]\n",
      " [6.84646035]]  bias  7.531977100077816 loss 0.0011801238353545882\n",
      "Iteration  90000  weights  [[6.20746473]\n",
      " [6.84542367]]  bias  7.534543189958604 loss 0.0010927654868584272\n",
      "Iteration  91000  weights  [[6.20646715]\n",
      " [6.84442609]]  bias  7.537012476890898 loss 0.0010118738165394495\n",
      "Iteration  92000  weights  [[6.2055072 ]\n",
      " [6.84346614]]  bias  7.539388612660629 loss 0.0009369701302894891\n",
      "Iteration  93000  weights  [[6.20458347]\n",
      " [6.84254241]]  bias  7.5416751112940315 loss 0.000867611169204014\n",
      "Iteration  94000  weights  [[6.20369458]\n",
      " [6.84165352]]  bias  7.5438753542545225 loss 0.0008033864864990195\n",
      "Iteration  95000  weights  [[6.20283923]\n",
      " [6.84079817]]  bias  7.545992595443499 loss 0.0007439160186025835\n",
      "Iteration  96000  weights  [[6.20201614]\n",
      " [6.83997508]]  bias  7.548029966012495 loss 0.0006888478360458217\n",
      "Iteration  97000  weights  [[6.20122411]\n",
      " [6.83918305]]  bias  7.549990478993719 loss 0.0006378560608449358\n",
      "Iteration  98000  weights  [[6.20046195]\n",
      " [6.83842089]]  bias  7.55187703375606 loss 0.0005906389380447212\n",
      "Iteration  99000  weights  [[6.19972854]\n",
      " [6.83768748]]  bias  7.553692420292836 loss 0.0005469170500198363\n",
      "Iteration  100000  weights  [[6.1990228 ]\n",
      " [6.83698174]]  bias  7.555439323347928 loss 0.0005064316629590209\n",
      "Iteration  101000  weights  [[6.19834369]\n",
      " [6.83630263]]  bias  7.557120326386133 loss 0.0004689431957520144\n",
      "Iteration  102000  weights  [[6.19769019]\n",
      " [6.83564913]]  bias  7.558737915413908 loss 0.00043422980221490985\n",
      "Iteration  103000  weights  [[6.19706134]\n",
      " [6.83502028]]  bias  7.560294482655776 loss 0.0004020860582683109\n",
      "Iteration  104000  weights  [[6.19645622]\n",
      " [6.83441516]]  bias  7.561792330092214 loss 0.000372321746294196\n",
      "Iteration  105000  weights  [[6.19587393]\n",
      " [6.83383287]]  bias  7.563233672863995 loss 0.0003447607294830868\n",
      "Iteration  106000  weights  [[6.1953136 ]\n",
      " [6.83327254]]  bias  7.564620642548102 loss 0.0003192399095049437\n",
      "Iteration  107000  weights  [[6.19477441]\n",
      " [6.83273335]]  bias  7.565955290310111 loss 0.0002956082613397744\n",
      "Iteration  108000  weights  [[6.19425556]\n",
      " [6.8322145 ]]  bias  7.56723958993757 loss 0.0002737259395540806\n",
      "Iteration  109000  weights  [[6.19375628]\n",
      " [6.83171522]]  bias  7.568475440759094 loss 0.0002534634507340943\n",
      "Iteration  110000  weights  [[6.19327584]\n",
      " [6.83123478]]  bias  7.569664670453165 loss 0.00023470088718189602\n",
      "Iteration  111000  weights  [[6.19281352]\n",
      " [6.83077246]]  bias  7.5708090377510695 loss 0.00021732721733436005\n",
      "Iteration  112000  weights  [[6.19236864]\n",
      " [6.83032758]]  bias  7.571910235037913 loss 0.0002012396287095388\n",
      "Iteration  113000  weights  [[6.19194055]\n",
      " [6.82989949]]  bias  7.572969890855355 loss 0.00018634291949200647\n",
      "Iteration  114000  weights  [[6.1915286 ]\n",
      " [6.82948754]]  bias  7.573989572310162 loss 0.00017254893515478812\n",
      "Iteration  115000  weights  [[6.1911322 ]\n",
      " [6.82909114]]  bias  7.574970787391634 loss 0.00015977604678649523\n",
      "Iteration  116000  weights  [[6.19075075]\n",
      " [6.82870968]]  bias  7.575914987201886 loss 0.00014794866803301686\n",
      "Iteration  117000  weights  [[6.19038368]\n",
      " [6.82834262]]  bias  7.576823568101701 loss 0.00013699680780078754\n",
      "Iteration  118000  weights  [[6.19003047]\n",
      " [6.82798941]]  bias  7.577697873775738 loss 0.00012685565606736468\n",
      "Iteration  119000  weights  [[6.18969058]\n",
      " [6.82764952]]  bias  7.57853919721961 loss 0.00011746520035459125\n",
      "Iteration  120000  weights  [[6.18936351]\n",
      " [6.82732245]]  bias  7.579348782652034 loss 0.00010876987059224692\n",
      "Iteration  121000  weights  [[6.18904878]\n",
      " [6.82700772]]  bias  7.58012782735497 loss 0.00010071821026945843\n",
      "Iteration  122000  weights  [[6.18874592]\n",
      " [6.82670486]]  bias  7.580877483444197 loss 9.32625719296893e-05\n",
      "Iteration  123000  weights  [[6.18845449]\n",
      " [6.82641343]]  bias  7.58159885957319 loss 8.635883520626618e-05\n",
      "Iteration  124000  weights  [[6.18817405]\n",
      " [6.82613299]]  bias  7.582293022572666 loss 7.996614573123337e-05\n",
      "Iteration  125000  weights  [[6.18790419]\n",
      " [6.82586313]]  bias  7.582960999028359 loss 7.40466733695709e-05\n",
      "Iteration  126000  weights  [[6.18764452]\n",
      " [6.82560345]]  bias  7.5836037767991025 loss 6.856538835240504e-05\n",
      "Iteration  127000  weights  [[6.18739463]\n",
      " [6.82535357]]  bias  7.5842223064778755 loss 6.348985397975504e-05\n",
      "Iteration  128000  weights  [[6.18715418]\n",
      " [6.82511312]]  bias  7.584817502797564 loss 5.8790034669521334e-05\n",
      "Iteration  129000  weights  [[6.18692279]\n",
      " [6.82488173]]  bias  7.585390245983761 loss 5.443811821562471e-05\n",
      "Iteration  130000  weights  [[6.18670014]\n",
      " [6.82465907]]  bias  7.585941383056509 loss 5.0408351202859406e-05\n",
      "Iteration  131000  weights  [[6.18648588]\n",
      " [6.82444482]]  bias  7.5864717290828745 loss 4.667688660612723e-05\n",
      "Iteration  132000  weights  [[6.1862797 ]\n",
      " [6.82423864]]  bias  7.586982068382484 loss 4.322164266940831e-05\n",
      "Iteration  133000  weights  [[6.18608131]\n",
      " [6.82404025]]  bias  7.5874731556873565 loss 4.002217223263917e-05\n",
      "Iteration  134000  weights  [[6.1858904 ]\n",
      " [6.82384933]]  bias  7.587945717258026 loss 3.7059541731795516e-05\n",
      "Iteration  135000  weights  [[6.18570669]\n",
      " [6.82366562]]  bias  7.588400451957661 loss 3.431621915435382e-05\n",
      "Iteration  136000  weights  [[6.1855299 ]\n",
      " [6.82348884]]  bias  7.588838032285563 loss 3.1775970290509716e-05\n",
      "Iteration  137000  weights  [[6.18535979]\n",
      " [6.82331873]]  bias  7.589259105371758 loss 2.9423762663375547e-05\n",
      "Iteration  138000  weights  [[6.1851961 ]\n",
      " [6.82315504]]  bias  7.589664293933964 loss 2.7245676571154272e-05\n",
      "Iteration  139000  weights  [[6.18503858]\n",
      " [6.82299752]]  bias  7.590054197198551 loss 2.5228822714297983e-05\n",
      "Iteration  140000  weights  [[6.184887  ]\n",
      " [6.82284594]]  bias  7.590429391786758 loss 2.336126592003459e-05\n",
      "Iteration  141000  weights  [[6.18474115]\n",
      " [6.82270008]]  bias  7.590790432567397 loss 2.1631954513544888e-05\n",
      "Iteration  142000  weights  [[6.18460079]\n",
      " [6.82255973]]  bias  7.591137853477452 loss 2.0030654917329423e-05\n",
      "Iteration  143000  weights  [[6.18446573]\n",
      " [6.82242467]]  bias  7.591472168311716 loss 1.8547891091628254e-05\n",
      "Iteration  144000  weights  [[6.18433576]\n",
      " [6.8222947 ]]  bias  7.591793871482637 loss 1.7174888458089598e-05\n",
      "Iteration  145000  weights  [[6.1842107 ]\n",
      " [6.82216964]]  bias  7.5921034387514865 loss 1.5903521974044984e-05\n",
      "Iteration  146000  weights  [[6.18409035]\n",
      " [6.82204929]]  bias  7.592401327931966 loss 1.4726268050983656e-05\n",
      "Iteration  147000  weights  [[6.18397455]\n",
      " [6.82193349]]  bias  7.592687979567274 loss 1.363616003192078e-05\n",
      "Iteration  148000  weights  [[6.18386311]\n",
      " [6.82182205]]  bias  7.592963817581568 loss 1.2626746964795807e-05\n",
      "Iteration  149000  weights  [[6.18375588]\n",
      " [6.82171482]]  bias  7.593229249906909 loss 1.1692055427639255e-05\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "model = LinearRegression(training_features, training_labels.T , learning_rate=0.0001)\n",
    "model.train(150000,True)\n",
    "\n",
    "values = model.trainingLoss\n",
    "x = np.arange(1, len(values) + 1)\n",
    "\n",
    "# Plotting\n",
    "plt.plot(x, values, marker='o', linestyle='-', color='blue')\n",
    "\n",
    "# Labels and title\n",
    "plt.xlabel(\"Iteration\")\n",
    "plt.ylabel(\"Loss\")\n",
    "plt.title(\"Loss value as a function of iteration\")\n",
    "plt.grid(True)\n",
    "plt.show()\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "42612d8d",
   "metadata": {},
   "source": [
    "#### Prediction Details"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "6ec392f1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicted weights  [[6.18365279]\n",
      " [6.82161173]]  bias  7.593484418542068\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "Length mismatch",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mValueError\u001b[39m                                Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[17]\u001b[39m\u001b[32m, line 2\u001b[39m\n\u001b[32m      1\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33m\"\u001b[39m\u001b[33mPredicted weights \u001b[39m\u001b[33m\"\u001b[39m, model.weight, \u001b[33m\"\u001b[39m\u001b[33m bias \u001b[39m\u001b[33m\"\u001b[39m, model.bias)\n\u001b[32m----> \u001b[39m\u001b[32m2\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33m\"\u001b[39m\u001b[33mPrediction loss\u001b[39m\u001b[33m\"\u001b[39m, \u001b[43mmodel\u001b[49m\u001b[43m.\u001b[49m\u001b[43mcalculateMseLoss\u001b[49m\u001b[43m(\u001b[49m\u001b[43mModelEquation\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtesting_attributes\u001b[49m\u001b[43m[\u001b[49m\u001b[32;43m0\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtesting_attributes\u001b[49m\u001b[43m[\u001b[49m\u001b[32;43m1\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m.\u001b[49m\u001b[43mpredict\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtesting_attributes\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/workspaces/ml-algorithms-raw/linear_regression/LinearRegression.py:50\u001b[39m, in \u001b[36mLinearRegression.calculateMseLoss\u001b[39m\u001b[34m(self, actual, predicted)\u001b[39m\n\u001b[32m     48\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mcalculateMseLoss\u001b[39m(\u001b[38;5;28mself\u001b[39m,actual, predicted):\n\u001b[32m     49\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(actual) != \u001b[38;5;28mlen\u001b[39m(predicted):\n\u001b[32m---> \u001b[39m\u001b[32m50\u001b[39m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[33m\"\u001b[39m\u001b[33mLength mismatch\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m     52\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m np.sum((actual - predicted) ** \u001b[32m2\u001b[39m) / \u001b[38;5;28mlen\u001b[39m(actual)\n",
      "\u001b[31mValueError\u001b[39m: Length mismatch"
     ]
    }
   ],
   "source": [
    "print(\"Predicted weights \", model.weight, \" bias \", model.bias)\n",
    "print(\"Prediction loss\", model.calculateMseLoss(ModelEquation(testing_attributes[0], testing_attributes[1]),model.predict(testing_attributes)))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b492f8d4",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
